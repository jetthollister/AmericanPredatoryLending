---
title: "Sentiment Analysis with Financial Blog Posts"
date: "By: Jett Hollister"
author: "American Predatory Lending"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

  We examined the attitudes of four economic pundits through their commentary on the financial blog sites: Calculated Risk, Grasping Reality, Caf√© Hayek and Marginal Revolution. These blogs represent a wide scope of backgrounds and ideologies. The fiscal opinions and ideologies of each blog can be found under data descriptions.
  The sentiment analysis, which tracks the amount of positive and negative words included within the blog posts, allows us to quantify the emotion of these experts over the course of the housing boom and subsequent collapse. We focused on how the language of the financially-aware aligned with, reacted to, and possibly foresaw the collapse of the subprime mortgage market.

**The technical write-ups related to this dataset:**

[Webscraping](To be added) (Python 3) 

[Blog Filtering](To be added) (Python 3)

**My analysis and findings:**

[Sentiment Analysis](To be added) 

[Blog Comparison](To be added)

```{r packages, include=FALSE}
options(stringsAsFactors = FALSE)

library(dplyr)
library(ggstance)
library(tidyverse)
library(ggplot2)
library(ggbeeswarm)
library(readr)
library(tidytext)
library(knitr)
library(kableExtra)
```

### Data

This dataset contains 36,982 individual blog posts from 5 different financial blog sites: Calculated Risk, Naked Capitalism, Grasping Reality, Marginal Revolution, and Cafe Hayek. The blog, title, date of publication, author, text are provided for each post.

```{r blogs.df, include=FALSE}
blogs.df <- read_csv("all_blogs_filtered_clean copy.csv") %>%
  select(-X1)
```

```{r df, echo=FALSE}
kable(blogs.df[1:5, ]) %>%
  kable_styling("striped") %>%
  scroll_box(width = "100%", height = "300px")
```

### Accounting for Negation Words

Negation words can skew the calculation of sentiment values because phrases like "not good" become "good" after the removal of stop words. We used bigrams to look at every combination of word pairs and find when a word was preceded by a negation. A new context variable was created to mark whether or not the word was preceded by a negation, which allowed the sentiment values to be adjusted based on this variable.

#### Tokenizing by Bigrams

The `unnest_tokens` function tokenized each body of text into pairs of consecutive words, and each pair was stored in an individual row. These pairs were separated to allow for easy iteration and identification of negation words.

```{r bigrams}
bigrams <- blogs.df %>%
  unnest_tokens(bigram, clean, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ")
```

```{r df_2, echo=FALSE}
kable(bigrams[0:100, ]) %>%
  kable_styling("striped") %>%
  scroll_box(width = "100%", height = "300px")
```
<p>&nbsp;</p>

#### Indicating Existence of Negation Words

When iterating over the word1, or preceding word, column, values were stored in the new `context` column. If the word was included within the list of negations, then the context value would be -1. Otherwise, it would be assigned a 1.

```{r negation}
negation_words <- c("not", "no", "never", "without", "nobody", "nor", "nothing",
                    "nowhere",  "don't", "can't",  "won't", "don", "won")

# Adds a column denoting whether the word was used with a positive or negative connotation
bigrams$context <- ifelse(bigrams$word1 %in% negation_words, -1, 1)
```

<p>&nbsp;</p>

#### Reassembling Dataframe

After negation words had been accounted for, all stopwords were then removed from tokenized words. Unnecessary columns, words less than 2 characters in length, and contractions (if any) were also removed from the dataset.

```{r tidy}
tidy_bigrams <- bigrams %>%
  select(-word1, -text, -title, -author) %>%
  anti_join(stop_words, by = c(word2 = "word"))

pre_sent <- filter(tidy_bigrams, word2 != "don", str_length(word2)>2)

pre_sent <- pre_sent %>% rename(word = word2)
```

### Sentiment Analysis

#### Assigning sentiment values to each blog

The AFINN lexicon was used to assign sentiment values to each word. This lexicon provides a value from -5 to 5 based on the word's positive/negative strength.

```{r pre sent}
sent <- pre_sent %>% 
  inner_join(get_sentiments("afinn"))
```

<p>&nbsp;</p>

#### Calculations for Each Post

Blog posts were grouped by month for ease of viewing and calculation purposes, and the sentiment values were aggregated by month in two different ways. The positive and negative scores were found by calculating the sum of positive values and negative values for each month, respectively.  `sent_ratio` "normalized" the values by finding the ratio of the positive score to the negative score per month. This number was subtracted by 1 to center neutral around the x-axis instead of around 1 for visualization purposes. `sent_add` just subtracts the negative score from the positive score.

```{r sent_blogs, fig.align="center"}
sent_blogs <- sent %>%
  mutate(adj = ifelse(sent$context == -1, (sent$value * -1), sent$value)) %>%
  mutate(sentiment = ifelse(sent$value < 0, "negative", "positive")) %>%
  group_by(blog) %>%
  count(month, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sent_ratio = (positive / negative) - 1) %>%
  mutate(sent_add = positive - negative)

ggplot(sent_blogs, aes(month, sent_ratio, fill = blog)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~blog, ncol = 2, scales = "free_x")

```

<p>&nbsp;</p>

#### Aggregate Calculations

The same calculations from `sent_blogs` were performed on `sent_all`, but this dataframe provided aggregate numbers for all blogs per month.

```{r all_blogs, fig.align="center"}
sent_all <- sent %>%
  mutate(adj = ifelse(sent$context == -1, (sent$value * -1), sent$value)) %>%
  mutate(sentiment = ifelse(sent$value < 0, "negative", "positive")) %>%
  filter(blog != "Naked Capitalism") %>%
  count(month, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sent_ratio = (positive / negative) - 1) %>%
  mutate(sent_add = positive - negative) %>%
  mutate(blog = "All Blogs")

ggplot(sent_all, aes(month, sent_ratio, fill = blog)) +
  geom_col(show.legend = FALSE)
```

<p>&nbsp;</p>

#### Concatenate Dataframes

```{r final}
final <- bind_rows(sent_blogs, sent_all)
```
```{r df_3, echo=FALSE}
kable(final[0:100, ]) %>%
  kable_styling("striped") %>%
  scroll_box(width = "100%", height = "300px")
```

<p>&nbsp;</p>
